\documentclass[11pt]{scrartcl} % Font size
\input{../structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{
	\normalfont\normalsize
	\textsc{Harvard Privacy Tools Project}\\ % Your university, school and/or department name(s)
	\vspace{25pt} % Whitespace
	\rule{\linewidth}{0.5pt}\\ % Thin top horizontal rule
	\vspace{20pt} % Whitespace
	{\huge Variance Sensitivity Proofs}\\ % The assignment title
	\vspace{12pt} % Whitespace
	\rule{\linewidth}{2pt}\\ % Thick bottom horizontal rule
	\vspace{12pt} % Whitespace
}

% \author{\LARGE} % Your name

\date{\normalsize\today} % Today's date (\today) or a custom date

\begin{document}

\maketitle 

\begin{definition}
Let variance be defined as 
$$ s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \mean)^2.$$
\end{definition}

\section{Neighboring Definition: Change One}
\subsection{$\ell_1$-sensitivity}
\begin{lemma}
\label{lemma:meansum}
For arbitrary $a$,
$$ \sum_{i=1}^n (x_i - a)^2 = \sum_{i=1}^n (x_i - \bar{x})^2 + n(a-\bar{x})^2.$$
\end{lemma}

\begin{proof}
\begin{align*}
\sum_{i=1}^n (x_i - a)^2 &= \sum_{i=1}^n \left( (x_i - \bar{x}) - (a-\bar{x}) \right)^2\\
	&= \sum_{i=1}^n \left( (x_i - \bar{x})^2 -2(x_i - \bar{x})(a-\bar{x}) + (a-\bar{x})^2\right)\\
	&= \sum_{i=1}^n (x_i - \bar{x})^2 - 2\sum_{i=1}^n \left(x_ia-x_i\bar{x} -\bar{x}a + \bar{x}^2\right) + \sum_{i=1}^n \left( a^2 -2a\bar{x} + \bar{x}^2\right)\\
	&=  \sum_{i=1}^n (x_i - \bar{x})^2 -2a\sum_{i=1}^n x_i + 2\bar{x}\sum_{i=1}^n x_i + 2\bar{x}an - 2\bar{x}^2n + a^2n-2a\bar{x}n+\bar{x}^2n\\
	&=  \sum_{i=1}^n (x_i - \bar{x})^2 + a^2n-2a\bar{x}n+\bar{x}^2n\\
	&=  \sum_{i=1}^n (x_i - \bar{x})^2 + n(a-\bar{x})^2
\end{align*}

\end{proof}

\begin{theorem}
Let 
$$ f(\x) = \sum_{i=1}^n (x_i - \bar{x})^2.$$
Then for $\x$ bounded between $m$ and $M,$ $f$ has sensitivity bounded above by
$$\frac{n-1}{n} (M-m)^2.$$
\end{theorem}

\begin{proof}
Consider databases $\xprime$ and $\xprimeprime$ which differ in a single point. For notational ease, call $\x$ the part of $\xprime$ and $\xprimeprime$
that is the same, and say that $\x$ contains $n$ points. WLOG say that the last data point in the database is the one that differs. I.e.,  
$\xprime = \x \cup \{x_{n+1}\},$ and $\xprimeprime = \x \cup \{x'_{n+1}\}$. This proof assumes that a ``neighboring database" is one that differs in a single
data-point, so we will ultimately be comparing $f(\xprime)$ and $f(\xprimeprime)$. However, it is useful to first write $f(\xprime)$ in terms of $f(\x)$.
Note that

\begin{align}
\label{eqn:meanprime}
\bar{x}' &= \frac{1}{n+1} \sum_{i=1}^{n+1} x_i \nonumber \\
	&= \frac{n\bar{x} + x_{n+1}}{n+1}.
\end{align}

Then,
\begin{align*}
f(\xprime) &= \sum_{i=1}^n (x_i - \bar{x}')^2 + (x_{n+1} - \bar{x}')^2\\
	&= \sum_{i=1}^n (x_i - \bar{x})^2 + n(\bar{x}'-\bar{x})^2 + (x_{n+1} - \bar{x}')^2 &&\text{(By Lemma \ref{lemma:meansum})}\\
	&= f(\x) + n\left( \frac{n\bar{x} + x_{n+1}}{n+1}-\bar{x}\right)^2 + \left(x_{n+1} - \frac{n\bar{x} + x_{n+1}}{n+1} \right)^2 &&\text{(By Equation \ref{eqn:meanprime})}\\
	&= f(\x) + n\left(\frac{x_{n+1}-\bar{x}}{n+1}\right)^2 + \left( \frac{nx_{n+1}-n\bar{x}}{n+1}\right)^2\\
	&= f(\x) + (x_{n+1}-\bar{x})^2 \frac{n+n^2}{(n+1)^2}\\
	&= f(\x) + (x_{n+1}-\bar{x})^2 \frac{n}{n+1}\\
\end{align*}

Now, to bound the sensitivity of $f$, note that

\begin{align*}
\left\vert f(\xprime) - f(\xprimeprime) \right\vert &= \left\vert (x_{n+1}-\bar{x})^2 \frac{n}{n+1} - (x_{n+1}'-\bar{x})^2 \frac{n}{n+1} \right\vert\\
	&\le (M-m)^2 \frac{n}{n+1}.
\end{align*}

Now, usually we're interested in sensitivities in terms of the total number of values in the database, which here is $n+1$. So, redefining $n$ as $n+1$ in the above equation gives

$$ (M-m)^2 \frac{n-1}{n}.$$
\end{proof}

\begin{corollary}
Sample variance has sensitivity bounded above by 
$$ \frac{(M-m)^2 }{n}.$$
\end{corollary}

\subsection{$\ell_2$-sensitivity}

\section{Neighboring Definition: Add/Drop One}
\subsection{$\ell_1$-sensitivity}
\subsection{$\ell_2$-sensitivity}

\bibliographystyle{alpha}
\bibliography{mean}

\end{document}